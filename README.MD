# âš½ Pipeline ETL de Posiciones de Ligas de FÃºtbol con Python, Airflow y MySQL

Este proyecto implementa un **pipeline ETL** para automatizar la extracciÃ³n, transformaciÃ³n y carga de posiciones de equipos de siete ligas de fÃºtbol desde ESPN hacia una base de datos MySQL, orquestado con **Apache Airflow** y desplegado en **Docker**.


## ğŸ§  DescripciÃ³n General

El pipeline obtiene diariamente las posiciones de las ligas de fÃºtbol desde las tablas pÃºblicas de ESPN, realiza la limpieza, transformaciÃ³n y enriquecimiento con metadatos de los equipos, y almacena el resultado final en MySQL. Esto permite consultas estructuradas, anÃ¡lisis exploratorios y potencial integraciÃ³n con herramientas de visualizaciÃ³n de datos.


## ğŸ—ï¸ Arquitectura del Proyecto

El flujo de trabajo estÃ¡ compuesto por scripts y mÃ³dulos locales, con un DAG de Airflow que orquesta la ejecuciÃ³n secuencial de las etapas de **Extract & Transform** y **Load**, garantizando reproducibilidad y modularidad.

Secuencia de procesamiento:

1. **Data Source**

   * URLs de las ligas en ESPN (7 ligas).
   * Ejemplo: `https://www.espn.com.co/futbol/posiciones/_/liga/eng.1`

2. **Extract & Transform**

   * Scripts: `extract_transform.py` â†’ `league_processing.py` â†’ `web_scraping.py`
   * Archivos locales en `data/`:

     * `df_ligas.csv` â†’ URLs y nombres de ligas.
     * `team_table.csv` â†’ CatÃ¡logo de equipos con ID Ãºnico.
   * Funciones: scraping, limpieza, concatenaciÃ³n y merge con metadatos de equipos.
   * Resultado: `team_positions_leagues.csv`.

3. **Load**

   * Scripts: `load.py` â†’ `db_loader.py` â†’ `connections.py`
   * FunciÃ³n: carga del dataset final a MySQL en la tabla `team_positions_leagues`.

4. **Orchestration**

   * DAG: `etl_espn_dag.py` (Airflow)
   * FunciÃ³n: ejecuta de forma secuencial los scripts de extracciÃ³n-transformaciÃ³n y carga a MySQL.
   * Entorno Dockerizado para reproducibilidad y escalabilidad.


## ğŸ§° TecnologÃ­as y Herramientas

* Lenguaje: Python 3.x
* OrquestaciÃ³n: Apache Airflow
* Base de Datos: MySQL
* Contenedores: Docker y Docker Compose
* LibrerÃ­as: Pandas, SQLAlchemy, Requests
* Archivos de entrada/salida: CSV (`df_ligas.csv`, `team_table.csv`, `team_positions_leagues.csv`)


## ğŸ“ Estructura del Repositorio

```bash
espn-etl-python-airflow/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ etl_espn_dag.py        # DAG de Airflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ df_ligas.csv           # URLs y nombres de ligas
â”‚   â”œâ”€â”€ team_positions_leagues.csv  # Output final del pipeline
â”‚   â””â”€â”€ team_table.csv         # Equipos con ID Ãºnico
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db_loader.py           # LÃ³gica de carga a MySQL
â”‚   â”œâ”€â”€ league_processing.py   # Procesamiento y concatenaciÃ³n de ligas
â”‚   â””â”€â”€ web_scraping.py        # ExtracciÃ³n y limpieza desde ESPN
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ extract_draw.ipynb     # Notebook exploratorio de extracciÃ³n
â”‚   â””â”€â”€ process_draw.ipynb     # Notebook exploratorio de procesamiento
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_transform.py   # Script maestro de extracciÃ³n y transformaciÃ³n
â”‚   â””â”€â”€ load.py                # Script maestro de carga
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ connections.py         # ConfiguraciÃ³n de conexiÃ³n a MySQL
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env-ejemplo               # Variables de entorno (ejemplo)
â”œâ”€â”€ docker-compose.yml         # OrquestaciÃ³n con Docker
â”œâ”€â”€ Dockerfile                 # Imagen base del proyecto
â””â”€â”€ requirements.txt           # Dependencias del proyecto
```


## âš™ï¸ Instrucciones de Uso

1. Clonar el repositorio:

```bash
git clone https://github.com/<tu-usuario>/espn-etl-python-airflow.git
cd espn-etl-python-airflow
```

2. Configurar variables de entorno:

```bash
cp .env-ejemplo .env
```

3. Levantar el entorno Docker:

```bash
docker-compose up --build
```

4. Acceder a Airflow Web UI: `http://localhost:8080`
5. Ejecutar el DAG **`etl_espn_dag`** para procesar y cargar los datos.
6. Verificar que la tabla `team_positions_leagues` en MySQL contiene el dataset final.


## ğŸ”„ Pipeline de Datos

| Etapa           | Script / MÃ³dulo                          | DescripciÃ³n                                                              |
| --------------- | ---------------------------------------- | ------------------------------------------------------------------------ |
| Fuente de datos | ESPN                                     | Extrae posiciones de equipos de 7 ligas de fÃºtbol desde tablas pÃºblicas. |
| TransformaciÃ³n  | extract\_transform.py                    | Orquesta extracciÃ³n y transformaciÃ³n.                                    |
| Procesamiento   | league\_processing.py                    | Limpieza, concatenaciÃ³n de ligas y merge con catÃ¡logo de equipos.        |
| Scraping        | web\_scraping.py                         | Extrae y formatea datos de las tablas de ESPN.                           |
| Almacenamiento  | team\_positions\_leagues.csv             | Dataset final en formato CSV local.                                      |
| Carga a BD      | load.py / db\_loader.py / connections.py | Inserta datos en MySQL.                                                  |
| OrquestaciÃ³n    | etl\_espn\_dag.py                        | Ejecuta el pipeline de forma secuencial con Airflow.                     |


## ğŸ“Š Output

* `team_positions_leagues.csv` y la tabla MySQL contienen:

  * Liga
  * Equipo
  * PosiciÃ³n
  * Puntos, victorias, empates, derrotas, goles
  * Metadatos de equipos


## ğŸ¯ Objetivos del Proyecto

* Implementar un pipeline ETL **modular y escalable**.
* Demostrar **web scraping, transformaciÃ³n y carga a base de datos**.
* Orquestar procesos con **Airflow** y asegurar reproducibilidad con **Docker**.
* Proveer un **dataset estructurado y enriquecido** listo para anÃ¡lisis o visualizaciÃ³n.


## ğŸ‘¤ Autor
Lemuel Azael Carrillo Barrera
Proyecto para portafolio de ingenierÃ­a de datos.

ğŸ”— [MÃ¡s sobre mÃ­](https://www.notion.so/Perfil-profesional-Lemuel-Azael-Carrillo-Barrera-2619ec6ab8528025b300d6099cd92add?source=copy_link)

## ğŸ“š Desarrollo completo del proyecto

Revisa todo el proceso paso a paso: desde la configuraciÃ³n inicial hasta la ejecuciÃ³n automatizada en AWS.

ğŸ” [Ver desarrollo completo en Notion](https://www.notion.so/ETL-from-ESPN-Football-to-MySQL-using-Python-and-Airflow-2619ec6ab8528031b9fdd6cd18da6760?source=copy_link)

## ğŸŒ Portafolio completo

Explora mÃ¡s proyectos y recursos en mis portafolios personales:

ğŸ”— [GitHub â€“ Portafolio](https://github.com/LemuelAzael/LemuelAzael)
ğŸ”— [Notion â€“ Portafolio](https://www.notion.so/Portafolio-Lemuel-Carrillo-2179ec6ab8528029ba54f3bf3363f993?source=copy_link)
